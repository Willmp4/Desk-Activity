{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "def load_data(directory):\n",
    "    session_data = []\n",
    "    for user_folder in os.listdir(directory):\n",
    "        print(\"Loading data for user\", user_folder)\n",
    "        user_path = os.path.join(directory, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for date_folder in os.listdir(user_path):\n",
    "                print(\"Loading data for date\", date_folder)\n",
    "                date_path = os.path.join(user_path, date_folder)\n",
    "                activity_file = 'events_data.json'\n",
    "                print(\"Loading data from\", date_path)\n",
    "                file_path = os.path.join(date_path, activity_file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        file_data = json.load(file)\n",
    "                        if isinstance(file_data, list):\n",
    "                            session_data.append(file_data)  # Each file is one session\n",
    "    return session_data\n",
    "\n",
    "def preprocess_data(session_data, threshold=5):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for session in session_data:\n",
    "        print(\"Processing session with\", len(session), \"events\")\n",
    "        features = []\n",
    "        label = None\n",
    "        for event in session:\n",
    "            # Check if the event is a focus level event and extract \n",
    "            if 'focus_level' in event['type']:\n",
    "                focus_level = event['data']['level']\n",
    "                label = 1 if focus_level > threshold else 0\n",
    "                if features and label is not None:  # Ensure there is data to add before resetting\n",
    "                    print(\"Adding session with\", len(features), \"events\")\n",
    "                    all_features.append(features)\n",
    "                    all_labels.append(label)\n",
    "                # Reset features and label for a new session starting after this event\n",
    "                features = []\n",
    "            # Extract features based on event type\n",
    "            else:\n",
    "                event_type = event['type']\n",
    "                if event_type == 'gaze_data':\n",
    "                    position = event['data'].get('adjusted_gaze_start_position', [0, 0])\n",
    "                elif event_type == 'mouse_movement':\n",
    "                    start_position = event['data'].get('start_position', [0, 0])\n",
    "                    end_position = event['data'].get('end_position', [0, 0])\n",
    "                    position = [(s + e) / 2 for s, e in zip(start_position, end_position)]  # Average position\n",
    "                elif event_type == 'mouse_click':\n",
    "                    position = event['data'].get('position', [0, 0])\n",
    "                else:\n",
    "                    position = [0, 0]\n",
    "\n",
    "                button = event['data'].get('button', 'None')\n",
    "                feature = [event['timestamp'], event_type, position, button]\n",
    "                features.append(feature)\n",
    "    return all_features, all_labels\n",
    "\n",
    "def encode_features(features):\n",
    "    # Collect all categories for fitting the encoder\n",
    "    all_categories = []\n",
    "    for session in features:\n",
    "        all_categories.extend([[feat[1], feat[3]] for feat in session])\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(all_categories)  # Fit encoder to all categories once\n",
    "\n",
    "    all_sessions = []\n",
    "    for session in features:\n",
    "        categorical_features = np.array([[feat[1], feat[3]] for feat in session])\n",
    "        categorical_encoded = encoder.transform(categorical_features).toarray()\n",
    "        position_data = np.array([feat[2] for feat in session])\n",
    "        encoded_session = np.hstack((position_data, categorical_encoded))\n",
    "        all_sessions.append(encoded_session)\n",
    "\n",
    "    return all_sessions\n",
    "\n",
    "\n",
    "def create_sequences(features, labels, sequence_length=100):\n",
    "\n",
    "    # Padding sequences\n",
    "    padded_features = pad_sequences(features, maxlen=sequence_length, padding='post', dtype='float32')\n",
    "    padded_labels = np.array(labels)  # No need to pad labels as there is one per sequence\n",
    "    print(padded_features.shape, padded_labels.shape)\n",
    "    return padded_features, padded_labels\n",
    "\n",
    "def build_and_train_model(sequences, labels):\n",
    "    # Convert list to numpy array if not already\n",
    "    sequences = np.array(sequences)\n",
    "    \n",
    "    # Check if sequences array is not empty\n",
    "    if sequences.size > 0:\n",
    "        print(sequences.shape)\n",
    "        model = Sequential()\n",
    "        # Ensure the input_shape matches the actual feature shape per timestep\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(sequences.shape[1], sequences.shape[2])))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        # Convert labels to numpy array if not already\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        model.fit(sequences, labels, epochs=20, batch_size=32)\n",
    "        return model\n",
    "    else:\n",
    "        print(\"No valid sequences to train on.\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    directory = '../../focus_level/'\n",
    "    session_data = load_data(directory)\n",
    "    processed_data, labels = preprocess_data(session_data)\n",
    "    encoded_features = encode_features(processed_data)\n",
    "    print(\"Number of encoded features:\", len(encoded_features))\n",
    "    X, y = create_sequences(encoded_features, labels)\n",
    "    print(y)\n",
    "\n",
    "    model = build_and_train_model(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding session with 1496 events\n",
      "Adding session with 5846 events\n",
      "Adding session with 4256 events\n",
      "Adding session with 217 events\n",
      "Adding session with 6886 events\n",
      "Adding session with 2813 events\n",
      "Adding session with 901 events\n",
      "Adding session with 4936 events\n",
      "Adding session with 2436 events\n",
      "Adding session with 8169 events\n",
      "Adding session with 8224 events\n",
      "Adding session with 11880 events\n",
      "Adding session with 9712 events\n",
      "Number of encoded features: 13\n",
      "(13, 100, 13) (13,)\n",
      "[0 1 0 0 0 0 0 1 0 1 1 1 1]\n",
      "(13, 100, 13)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6825 - accuracy: 0.6154\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6721 - accuracy: 0.6154\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6588 - accuracy: 0.6154\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6411 - accuracy: 0.6154\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6228 - accuracy: 0.6923\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6035 - accuracy: 0.6923\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5788 - accuracy: 0.6923\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5558 - accuracy: 0.7692\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5353 - accuracy: 0.8462\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5082 - accuracy: 0.8462\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4858 - accuracy: 0.8462\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4643 - accuracy: 0.8462\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4378 - accuracy: 0.8462\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4098 - accuracy: 0.8462\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3766 - accuracy: 0.8462\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3538 - accuracy: 0.9231\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3280 - accuracy: 0.9231\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3706 - accuracy: 0.8462\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3017 - accuracy: 0.9231\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3067 - accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def predict_focus(model, sequences):\n",
    "    return model.predict(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for user test\n",
      "Loading data for date test\n",
      "Loading data from ../../focus_level/test\\test\n",
      "Loading data for user wgoud\n",
      "Loading data for date 2024-04-12\n",
      "Loading data from ../../focus_level/wgoud\\2024-04-12\n",
      "Loading data for date 2024-04-14\n",
      "Loading data from ../../focus_level/wgoud\\2024-04-14\n",
      "Loading data for date 2024-04-16\n",
      "Loading data from ../../focus_level/wgoud\\2024-04-16\n",
      "Loading data for date 2024-04-21\n",
      "Loading data from ../../focus_level/wgoud\\2024-04-21\n",
      "Loading data for date 2024-04-23\n",
      "Loading data from ../../focus_level/wgoud\\2024-04-23\n",
      "Loading data for date 2024-04-25\n",
      "Loading data from ../../focus_level/wgoud\\2024-04-25\n",
      "Loading data for date 2024-04-29\n",
      "Loading data from ../../focus_level/wgoud\\2024-04-29\n",
      "Number of sessions: 1\n",
      "Processing session with 1254 events\n",
      "Adding session with 422 events\n",
      "Adding session with 581 events\n",
      "Adding session with 248 events\n",
      "(3, 100, 9) (3,)\n",
      "(3, 100, 9) (3,)\n",
      "1/1 [==============================] - 1s 765ms/step\n"
     ]
    }
   ],
   "source": [
    "directory = '../../focus_level/'\n",
    "data = load_data(directory)\n",
    "print(\"Number of sessions:\", len(data))\n",
    "processed_features, processed_labels = preprocess_data(data)\n",
    "encoded_features = encode_features(processed_features)\n",
    "X, y = create_sequences(encoded_features, processed_labels)\n",
    "print(X.shape, y.shape)\n",
    "predictions = predict_focus(model, X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
