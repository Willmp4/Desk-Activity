{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "def build_and_train_model(sequences, labels):\n",
    "    # Convert list to numpy array if not already\n",
    "    sequences = np.array(sequences)\n",
    "    \n",
    "    # Check if sequences array is not empty\n",
    "    if sequences.size > 0:\n",
    "        model = Sequential()\n",
    "        # Ensure the input_shape matches the actual feature shape per timestep\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(sequences.shape[1], sequences.shape[2])))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        # Convert labels to numpy array if not already\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        model.fit(sequences, labels, epochs=20, batch_size=32)\n",
    "        return model\n",
    "    else:\n",
    "        print(\"No valid sequences to train on.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_data(directory):\n",
    "    session_data = []\n",
    "    for user_folder in os.listdir(directory):\n",
    "        user_path = os.path.join(directory, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for date_folder in os.listdir(user_path):\n",
    "                date_path = os.path.join(user_path, date_folder)\n",
    "                activity_file = 'activity_log.json'\n",
    "                file_path = os.path.join(date_path, activity_file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        file_data = json.load(file)\n",
    "                        if isinstance(file_data, list):\n",
    "                            session_data.append(file_data)  # Each file is one session\n",
    "    return session_data\n",
    "\n",
    "def preprocess_data(session_data, threshold=5):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for session in session_data:\n",
    "        features = []\n",
    "        label = None\n",
    "        for event in session:\n",
    "            if 'level' in event['data']:  # Assuming focus level is in 'data'\n",
    "                focus_level = event['data']['level']\n",
    "                # Convert focus level to binary class\n",
    "                label = 1 if focus_level > threshold else 0\n",
    "            else:\n",
    "                feature = [\n",
    "                    event['timestamp'],\n",
    "                    event['type'],\n",
    "                    event['data'].get('position', [0, 0]),  # Defaulting to [0, 0] if none\n",
    "                    event['data'].get('button', 'None')  # Defaulting to 'None' if none\n",
    "                ]\n",
    "                features.append(feature)\n",
    "        if features and label is not None:\n",
    "            all_features.append(features)\n",
    "            all_labels.append(label)\n",
    "    \n",
    "    return all_features, all_labels\n",
    "\n",
    "\n",
    "def encode_features(features):\n",
    "    # Collect all categories for fitting the encoder\n",
    "    all_categories = []\n",
    "    for session in features:\n",
    "        all_categories.extend([[feat[1], feat[3]] for feat in session])\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(all_categories)  # Fit encoder to all categories once\n",
    "\n",
    "    all_sessions = []\n",
    "    for session in features:\n",
    "        categorical_features = np.array([[feat[1], feat[3]] for feat in session])\n",
    "        categorical_encoded = encoder.transform(categorical_features).toarray()\n",
    "        position_data = np.array([feat[2] for feat in session])\n",
    "        encoded_session = np.hstack((position_data, categorical_encoded))\n",
    "        all_sessions.append(encoded_session)\n",
    "\n",
    "    return all_sessions\n",
    "\n",
    "\n",
    "def create_sequences(features, labels, sequence_length=100):\n",
    "    # Padding sequences\n",
    "    padded_features = pad_sequences(features, maxlen=sequence_length, padding='post', dtype='float32')\n",
    "    padded_labels = np.array(labels)  # No need to pad labels as there is one per sequence\n",
    "    return padded_features, padded_labels\n",
    "\n",
    "def build_and_train_model(sequences, labels):\n",
    "    # Convert list to numpy array if not already\n",
    "    sequences = np.array(sequences)\n",
    "    \n",
    "    # Check if sequences array is not empty\n",
    "    if sequences.size > 0:\n",
    "        model = Sequential()\n",
    "        # Ensure the input_shape matches the actual feature shape per timestep\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(sequences.shape[1], sequences.shape[2])))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        # Convert labels to numpy array if not already\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        model.fit(sequences, labels, epochs=20, batch_size=32)\n",
    "        return model\n",
    "    else:\n",
    "        print(\"No valid sequences to train on.\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    directory = '../../focus_level/'\n",
    "    session_data = load_data(directory)\n",
    "    print(\"Number of sessions:\", len(session_data))\n",
    "    processed_data, labels = preprocess_data(session_data)\n",
    "    encoded_features = encode_features(processed_data)\n",
    "    print(\"Number of encoded features:\", len(encoded_features))\n",
    "    X, y = create_sequences(encoded_features, labels)\n",
    "    print(y)\n",
    "\n",
    "    build_and_train_model(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions: 3\n",
      "Number of encoded features: 3\n",
      "[0 1 0]\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6978 - accuracy: 0.3333\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6716 - accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6502 - accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6396 - accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6285 - accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6145 - accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.5991 - accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5829 - accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5671 - accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5507 - accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5328 - accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5123 - accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4889 - accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4636 - accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4355 - accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4040 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3698 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3324 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2960 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2630 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
