{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_data(directory):\n",
    "    session_data = []\n",
    "    for user_folder in os.listdir(directory):\n",
    "        user_path = os.path.join(directory, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for date_folder in os.listdir(user_path):\n",
    "                date_path = os.path.join(user_path, date_folder)\n",
    "                activity_file = 'activity_log.json'\n",
    "                file_path = os.path.join(date_path, activity_file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        file_data = json.load(file)\n",
    "                        if isinstance(file_data, list):\n",
    "                            session_data.append(file_data)  # Each file is one session\n",
    "    return session_data\n",
    "\n",
    "def preprocess_data(session_data, threshold=5):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for session in session_data:\n",
    "        features = []\n",
    "        label = None\n",
    "        for event in session:\n",
    "            # Check if the event is a focus level event and extract \n",
    "            if 'focus_level' in event['type']:\n",
    "                focus_level = event['data']['level']\n",
    "                label = 1 if focus_level > threshold else 0\n",
    "                if features and label is not None:  # Ensure there is data to add before resetting\n",
    "                    all_features.append(features)\n",
    "                    all_labels.append(label)\n",
    "                # Reset features and label for a new session starting after this event\n",
    "                features = []\n",
    "            # Extract features based on event type\n",
    "            else:\n",
    "                event_type = event['type']\n",
    "                if event_type == 'active_window':\n",
    "                    continue\n",
    "                time_delta = event.get('time_delta', event['data'].get('time_delta', 0))\n",
    "                if event_type == 'gaze_data':\n",
    "                    position = event['data'].get('adjusted_gaze_start_position', [0, 0])\n",
    "                elif event_type == 'mouse_movement':\n",
    "                    start_position = event['data'].get('start_position', [0, 0])\n",
    "                    end_position = event['data'].get('end_position', [0, 0])\n",
    "                    position = [(s + e) / 2 for s, e in zip(start_position, end_position)]  # Average position\n",
    "                elif event_type == 'mouse_click':\n",
    "                    position = event['data'].get('position', [0, 0])\n",
    "                elif event_type == 'keyboard_session':\n",
    "                    start_time = event['data'].get('start_time', event['timestamp'])\n",
    "                    end_time = event['data'].get('end_time', event['timestamp'])\n",
    "                    duration = (np.datetime64(end_time) - np.datetime64(start_time)).astype('timedelta64[ms]').astype(int)\n",
    "                    position = [duration, 0] \n",
    "                else:\n",
    "                    position = [0, 0]\n",
    "                button = event['data'].get('button', 'None')\n",
    "\n",
    "                feature = [event['timestamp'], event_type, position, button, time_delta]\n",
    "                features.append(feature)\n",
    "    return all_features, all_labels\n",
    "\n",
    "def encode_features(features):\n",
    "    all_categories = []\n",
    "    all_time_deltas = []\n",
    "    for session in features:\n",
    "        all_categories.extend([[feat[1], feat[3]] for feat in session])\n",
    "        all_time_deltas.extend([feat[4] for feat in session])\n",
    "\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(all_categories)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    all_time_deltas = np.array(all_time_deltas).reshape(-1, 1)\n",
    "    scaler.fit(all_time_deltas)\n",
    "    all_time_deltas_normalized = scaler.transform(all_time_deltas).flatten()\n",
    "\n",
    "    all_sessions = []\n",
    "    time_delta_index = 0\n",
    "    for session in features:\n",
    "        categorical_features = np.array([[feat[1], feat[3]] for feat in session])\n",
    "        categorical_encoded = encoder.transform(categorical_features).toarray()\n",
    "        position_data = np.array([feat[2] for feat in session])\n",
    "        time_deltas = np.array([all_time_deltas_normalized[time_delta_index:time_delta_index+len(session)]])\n",
    "        time_delta_index += len(session)\n",
    "        encoded_session = np.hstack((position_data, categorical_encoded, time_deltas.T))\n",
    "        all_sessions.append(encoded_session)\n",
    "\n",
    "    return all_sessions, encoder, scaler\n",
    "\n",
    "def create_sequences(features, labels, sequence_length=100):\n",
    "\n",
    "    # Padding sequences\n",
    "    padded_features = pad_sequences(features, maxlen=sequence_length, padding='post', dtype='float32')\n",
    "    padded_labels = np.array(labels)  # No need to pad labels as there is one per sequence\n",
    "    print(padded_features.shape, padded_labels.shape)\n",
    "    return padded_features, padded_labels\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "def build_and_train_model(X_train, y_train, X_test, y_test):\n",
    "    # Convert lists to numpy arrays if not already\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Check if sequences array is not empty\n",
    "    if X_train.size > 0:\n",
    "        print(X_train.shape)\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Add bidirectional LSTMs and more layers\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Bidirectional(LSTM(84)))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "\n",
    "        # Add dense layers\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        # Compile the model with an optimizer and loss function\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))\n",
    "        return model\n",
    "    else:\n",
    "        print(\"No valid sequences to train on.\")\n",
    "        return None\n",
    "\n",
    "import pickle\n",
    "def save_model_and_preprocessors(model, encoder, scaler, model_path, encoder_path, scaler_path):\n",
    "    # Save the Keras model\n",
    "    model.save(model_path)\n",
    "    # Save the preprocessors\n",
    "    with open(encoder_path, 'wb') as f:\n",
    "        pickle.dump(encoder, f)\n",
    "    with open(scaler_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "def main():\n",
    "    focus_level_directory = '../../focus_level/'\n",
    "    synthetic_data_directory = 'synthetic_data/'\n",
    "\n",
    "    # Load data from both directories\n",
    "    session_data_focus = load_data(focus_level_directory)\n",
    "    session_data_synthetic = load_data(synthetic_data_directory)\n",
    "    print(\"Loaded\", len(session_data_focus), \"focus level sessions and\", len(session_data_synthetic), \"synthetic sessions.\")\n",
    "\n",
    "    # Combine the data into one list\n",
    "    session_data = session_data_focus + session_data_synthetic\n",
    "\n",
    "    # Preprocess the combined data\n",
    "    processed_data, labels = preprocess_data(session_data)\n",
    "    encoded_features, encoder, scaler = encode_features(processed_data)\n",
    "    X, y = create_sequences(encoded_features, labels)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build and train a new model with the training set\n",
    "    model = build_and_train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Save model and preprocessors\n",
    "    version = \"_v2\"\n",
    "    model_path = f'model{version}.h5'\n",
    "    encoder_path = f'encoder{version}.pkl'\n",
    "    scaler_path = f'scaler{version}.pkl'\n",
    "    save_model_and_preprocessors(model, encoder, scaler, model_path, encoder_path, scaler_path)\n",
    "\n",
    "    return model, encoder, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 focus level sessions and 2000 synthetic sessions.\n",
      "(2029, 100, 15) (2029,)\n",
      "(1623, 100, 15)\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 16s 132ms/step - loss: 0.5578 - accuracy: 0.7320 - val_loss: 1.1728 - val_accuracy: 0.5394\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.4587 - accuracy: 0.7954 - val_loss: 0.8085 - val_accuracy: 0.4828\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.4388 - accuracy: 0.8022 - val_loss: 2.6951 - val_accuracy: 0.5148\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.4457 - accuracy: 0.7954 - val_loss: 1.2300 - val_accuracy: 0.5172\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.4261 - accuracy: 0.8041 - val_loss: 1.7850 - val_accuracy: 0.4877\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.4320 - accuracy: 0.8028 - val_loss: 2.8254 - val_accuracy: 0.4852\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.4236 - accuracy: 0.8053 - val_loss: 0.7894 - val_accuracy: 0.7167\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 0.4069 - accuracy: 0.8170 - val_loss: 1.0199 - val_accuracy: 0.5443\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.4095 - accuracy: 0.8145 - val_loss: 0.7306 - val_accuracy: 0.6970\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.4412 - accuracy: 0.7979 - val_loss: 2.1894 - val_accuracy: 0.4778\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 0.4080 - accuracy: 0.8152 - val_loss: 0.9980 - val_accuracy: 0.6872\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.4001 - accuracy: 0.8250 - val_loss: 0.6396 - val_accuracy: 0.7389\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.4046 - accuracy: 0.8084 - val_loss: 0.5408 - val_accuracy: 0.7709\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.4085 - accuracy: 0.8102 - val_loss: 1.9354 - val_accuracy: 0.5443\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.3973 - accuracy: 0.8145 - val_loss: 2.0600 - val_accuracy: 0.5271\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.3785 - accuracy: 0.8250 - val_loss: 1.6303 - val_accuracy: 0.5739\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.3757 - accuracy: 0.8269 - val_loss: 0.9704 - val_accuracy: 0.7044\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 0.3739 - accuracy: 0.8238 - val_loss: 1.3141 - val_accuracy: 0.5714\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.3870 - accuracy: 0.8115 - val_loss: 0.7159 - val_accuracy: 0.7389\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.3670 - accuracy: 0.8262 - val_loss: 0.8140 - val_accuracy: 0.7044\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 3s 99ms/step - loss: 0.3400 - accuracy: 0.8380 - val_loss: 1.4116 - val_accuracy: 0.6158\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.3269 - accuracy: 0.8417 - val_loss: 2.1019 - val_accuracy: 0.5246\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.3638 - accuracy: 0.8269 - val_loss: 0.7496 - val_accuracy: 0.6897\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 0.3107 - accuracy: 0.8558 - val_loss: 0.8969 - val_accuracy: 0.6429\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.3020 - accuracy: 0.8558 - val_loss: 0.7697 - val_accuracy: 0.6995\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.2979 - accuracy: 0.8675 - val_loss: 0.7198 - val_accuracy: 0.7488\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.2914 - accuracy: 0.8644 - val_loss: 0.5155 - val_accuracy: 0.7808\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.2584 - accuracy: 0.8718 - val_loss: 0.5557 - val_accuracy: 0.7734\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.2415 - accuracy: 0.8940 - val_loss: 0.6270 - val_accuracy: 0.7512\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.2437 - accuracy: 0.8946 - val_loss: 0.6607 - val_accuracy: 0.7635\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 0.2695 - accuracy: 0.8663 - val_loss: 0.6084 - val_accuracy: 0.7611\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.2472 - accuracy: 0.8835 - val_loss: 0.6710 - val_accuracy: 0.6995\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.2401 - accuracy: 0.8983 - val_loss: 0.5908 - val_accuracy: 0.7635\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.2160 - accuracy: 0.9150 - val_loss: 0.7719 - val_accuracy: 0.7709\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.2080 - accuracy: 0.9162 - val_loss: 0.7629 - val_accuracy: 0.7266\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.1731 - accuracy: 0.9291 - val_loss: 0.7964 - val_accuracy: 0.7365\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.1779 - accuracy: 0.9242 - val_loss: 0.7046 - val_accuracy: 0.7340\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.1882 - accuracy: 0.9224 - val_loss: 0.7943 - val_accuracy: 0.6995\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.1980 - accuracy: 0.9205 - val_loss: 0.7136 - val_accuracy: 0.7069\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.1148 - accuracy: 0.9606 - val_loss: 0.9423 - val_accuracy: 0.7094\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1124 - accuracy: 0.9550 - val_loss: 1.1530 - val_accuracy: 0.6675\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 0.1497 - accuracy: 0.9415 - val_loss: 0.7950 - val_accuracy: 0.7463\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 2s 73ms/step - loss: 0.1178 - accuracy: 0.9538 - val_loss: 1.0323 - val_accuracy: 0.6897\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.0995 - accuracy: 0.9661 - val_loss: 0.9492 - val_accuracy: 0.7365\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.1276 - accuracy: 0.9482 - val_loss: 0.8705 - val_accuracy: 0.7463\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.1355 - accuracy: 0.9489 - val_loss: 0.9280 - val_accuracy: 0.7340\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.1489 - accuracy: 0.9396 - val_loss: 0.8057 - val_accuracy: 0.7734\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.1160 - accuracy: 0.9538 - val_loss: 1.0602 - val_accuracy: 0.6995\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 0.0759 - accuracy: 0.9754 - val_loss: 1.5301 - val_accuracy: 0.6576\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.0949 - accuracy: 0.9655 - val_loss: 1.3798 - val_accuracy: 0.7118\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
